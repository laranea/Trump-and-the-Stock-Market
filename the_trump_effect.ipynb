{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "C:\\Users\\bobbyd\\Anaconda2\\envs\\neural_net\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "    Author: Robert Dwyer\n",
    "    Date: 10/25/2017\n",
    "    A multivariate LSTM neural Network designed to predict the current days S&P500 value based on the previous days closing\n",
    "    price, volume traded, and the sentiment of Donald Trump's tweets.\n",
    "'''\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import concatenate\n",
    "from numpy import sqrt\n",
    "import math\n",
    "from sklearn.preprocessing import Imputer\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from subprocess import check_output\n",
    "from numpy import newaxis\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>com</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016-01-01</td>\n",
       "      <td>6.4942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016-01-02</td>\n",
       "      <td>2.8296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016-01-03</td>\n",
       "      <td>0.1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016-01-04</td>\n",
       "      <td>2.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-01-05</td>\n",
       "      <td>8.0538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   created_at     com\n",
       "0  2016-01-01  6.4942\n",
       "1  2016-01-02  2.8296\n",
       "2  2016-01-03  0.1894\n",
       "3  2016-01-04  2.0465\n",
       "4  2016-01-05  8.0538"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump = pd.read_csv('trump_sent.csv')\n",
    "trump.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Low</th>\n",
       "      <th>High</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aug 22, 2017</td>\n",
       "      <td>2433.75</td>\n",
       "      <td>2433.67</td>\n",
       "      <td>2454.77</td>\n",
       "      <td>2452.51</td>\n",
       "      <td>1,588,714,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aug 18, 2017</td>\n",
       "      <td>2427.64</td>\n",
       "      <td>2420.69</td>\n",
       "      <td>2440.27</td>\n",
       "      <td>2425.55</td>\n",
       "      <td>1,962,081,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aug 17, 2017</td>\n",
       "      <td>2462.95</td>\n",
       "      <td>2430.01</td>\n",
       "      <td>2465.02</td>\n",
       "      <td>2430.01</td>\n",
       "      <td>1,929,351,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aug 15, 2017</td>\n",
       "      <td>2468.66</td>\n",
       "      <td>2461.61</td>\n",
       "      <td>2468.90</td>\n",
       "      <td>2464.61</td>\n",
       "      <td>1,689,634,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aug 14, 2017</td>\n",
       "      <td>2454.96</td>\n",
       "      <td>2454.96</td>\n",
       "      <td>2468.22</td>\n",
       "      <td>2465.84</td>\n",
       "      <td>1,586,224,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date     Open      Low     High    Close         Volume\n",
       "0  Aug 22, 2017  2433.75  2433.67  2454.77  2452.51  1,588,714,000\n",
       "1  Aug 18, 2017  2427.64  2420.69  2440.27  2425.55  1,962,081,000\n",
       "2  Aug 17, 2017  2462.95  2430.01  2465.02  2430.01  1,929,351,000\n",
       "3  Aug 15, 2017  2468.66  2461.61  2468.90  2464.61  1,689,634,000\n",
       "4  Aug 14, 2017  2454.96  2454.96  2468.22  2465.84  1,586,224,000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nyse = pd.read_csv('C:/Users/bobbyd/Desktop/data_science/git_repo/Trump-and-the-Stock-Market/nyse1.csv', skipfooter=2, engine = 'python')\n",
    "nyse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2043.94</td>\n",
       "      <td>482596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>2043.94</td>\n",
       "      <td>482596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>2043.94</td>\n",
       "      <td>482596000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>2012.66</td>\n",
       "      <td>802072000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>2012.66</td>\n",
       "      <td>802072000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close     Volume\n",
       "Date                          \n",
       "2016-01-01  2043.94  482596000\n",
       "2016-01-02  2043.94  482596000\n",
       "2016-01-03  2043.94  482596000\n",
       "2016-01-04  2012.66  802072000\n",
       "2016-01-05  2012.66  802072000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#preprocess Stock data\n",
    "nyse.index = pd.DatetimeIndex(nyse['Date'])\n",
    "nyse.sort_index(ascending=True, inplace=True)\n",
    "nyse.drop('Date', axis=1, inplace=True)\n",
    "nyse = nyse[['Close','Volume']]\n",
    "nyse = nyse.resample('D').fillna('ffill')\n",
    "nyse['Volume'] = nyse['Volume'].apply(lambda x: x.replace(',', ''))\n",
    "nyse= nyse.loc['2016-01-01':, :]\n",
    "nyse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocess sentiment data\n",
    "trump.index = pd.DatetimeIndex(trump['created_at'])\n",
    "trump.sort_index(ascending=True, inplace=True)\n",
    "trump.drop('created_at', axis=1, inplace=True)\n",
    "trump=trump.loc[:'2017-08-22',:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((600, 1), (600, 2))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trump.shape, nyse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>2043.94</td>\n",
       "      <td>482596000</td>\n",
       "      <td>6.4942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>2043.94</td>\n",
       "      <td>482596000</td>\n",
       "      <td>2.8296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>2043.94</td>\n",
       "      <td>482596000</td>\n",
       "      <td>0.1894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>2012.66</td>\n",
       "      <td>802072000</td>\n",
       "      <td>2.0465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>2012.66</td>\n",
       "      <td>802072000</td>\n",
       "      <td>8.0538</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Close     Volume  sentiment\n",
       "2016-01-01  2043.94  482596000     6.4942\n",
       "2016-01-02  2043.94  482596000     2.8296\n",
       "2016-01-03  2043.94  482596000     0.1894\n",
       "2016-01-04  2012.66  802072000     2.0465\n",
       "2016-01-05  2012.66  802072000     8.0538"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.concat([nyse, trump], axis=1)\n",
    "df = df.rename(columns={'com': 'sentiment'})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = Imputer(strategy='median')\n",
    "df = imputer.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>var1(t-1)</th>\n",
       "      <th>var2(t-1)</th>\n",
       "      <th>var3(t-1)</th>\n",
       "      <th>var1(t)</th>\n",
       "      <th>var2(t)</th>\n",
       "      <th>var3(t)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.331191</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.530415</td>\n",
       "      <td>0.331191</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.377457</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.331191</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.377457</td>\n",
       "      <td>0.331191</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.267257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.331191</td>\n",
       "      <td>0.063974</td>\n",
       "      <td>0.267257</td>\n",
       "      <td>0.282975</td>\n",
       "      <td>0.156613</td>\n",
       "      <td>0.344771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282975</td>\n",
       "      <td>0.156613</td>\n",
       "      <td>0.344771</td>\n",
       "      <td>0.282975</td>\n",
       "      <td>0.156613</td>\n",
       "      <td>0.595512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.282975</td>\n",
       "      <td>0.156613</td>\n",
       "      <td>0.595512</td>\n",
       "      <td>0.248447</td>\n",
       "      <td>0.137112</td>\n",
       "      <td>0.370395</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   var1(t-1)  var2(t-1)  var3(t-1)   var1(t)   var2(t)   var3(t)\n",
       "1   0.331191   0.063974   0.530415  0.331191  0.063974  0.377457\n",
       "2   0.331191   0.063974   0.377457  0.331191  0.063974  0.267257\n",
       "3   0.331191   0.063974   0.267257  0.282975  0.156613  0.344771\n",
       "4   0.282975   0.156613   0.344771  0.282975  0.156613  0.595512\n",
       "5   0.282975   0.156613   0.595512  0.248447  0.137112  0.370395"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A function that will covert a time series database into a supervised learning database\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "            cols.append(df.shift(i))\n",
    "            names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    "\n",
    "\n",
    "df = df.astype('float32')\n",
    "\n",
    "\n",
    "\n",
    "# scale data, reframe for supervised learning and drop target variable\n",
    "scaler = MinMaxScaler(feature_range=(0,1))\n",
    "scaled  = scaler.fit_transform(df)\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "reframed.head()\n",
    "reframed.drop(reframed.columns[[3,4]], axis=1)\n",
    "reframed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 1, 5) (300,) (299, 1, 5) (299,)\n"
     ]
    }
   ],
   "source": [
    "#split data into training and test\n",
    "values= reframed.values\n",
    "n_train_hours =30*10\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:,:]\n",
    "\n",
    "#split data into inputs and outputs\n",
    "train_X, train_y = train[:,:-1], train[:,-1] \n",
    "test_X, test_y = test[:,:-1], test[:,-1]\n",
    "\n",
    "#required input shape for a LSTM is 3D\n",
    "train_X = train_X.reshape(train_X.shape[0],1, train_X.shape[1])\n",
    "test_X = test_X.reshape(test_X.shape[0],1, test_X.shape[1])\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 300 samples, validate on 299 samples\n",
      "Epoch 1/50\n",
      "300/300 [==============================] - 0s - loss: 0.3480 - val_loss: 0.2972\n",
      "Epoch 2/50\n",
      "300/300 [==============================] - 0s - loss: 0.3158 - val_loss: 0.2457\n",
      "Epoch 3/50\n",
      "300/300 [==============================] - 0s - loss: 0.2837 - val_loss: 0.1934\n",
      "Epoch 4/50\n",
      "300/300 [==============================] - 0s - loss: 0.2513 - val_loss: 0.1400\n",
      "Epoch 5/50\n",
      "300/300 [==============================] - 0s - loss: 0.2185 - val_loss: 0.0920\n",
      "Epoch 6/50\n",
      "300/300 [==============================] - 0s - loss: 0.1859 - val_loss: 0.0675\n",
      "Epoch 7/50\n",
      "300/300 [==============================] - 0s - loss: 0.1559 - val_loss: 0.0800\n",
      "Epoch 8/50\n",
      "300/300 [==============================] - 0s - loss: 0.1312 - val_loss: 0.1166\n",
      "Epoch 9/50\n",
      "300/300 [==============================] - 0s - loss: 0.1136 - val_loss: 0.1614\n",
      "Epoch 10/50\n",
      "300/300 [==============================] - 0s - loss: 0.1042 - val_loss: 0.1994\n",
      "Epoch 11/50\n",
      "300/300 [==============================] - 0s - loss: 0.1012 - val_loss: 0.2239\n",
      "Epoch 12/50\n",
      "300/300 [==============================] - 0s - loss: 0.1007 - val_loss: 0.2342\n",
      "Epoch 13/50\n",
      "300/300 [==============================] - 0s - loss: 0.1004 - val_loss: 0.2328\n",
      "Epoch 14/50\n",
      "300/300 [==============================] - 0s - loss: 0.0997 - val_loss: 0.2247\n",
      "Epoch 15/50\n",
      "300/300 [==============================] - 0s - loss: 0.0990 - val_loss: 0.2140\n",
      "Epoch 16/50\n",
      "300/300 [==============================] - 0s - loss: 0.0987 - val_loss: 0.2038\n",
      "Epoch 17/50\n",
      "300/300 [==============================] - 0s - loss: 0.0987 - val_loss: 0.1961\n",
      "Epoch 18/50\n",
      "300/300 [==============================] - 0s - loss: 0.0990 - val_loss: 0.1912\n",
      "Epoch 19/50\n",
      "300/300 [==============================] - 0s - loss: 0.0991 - val_loss: 0.1892\n",
      "Epoch 20/50\n",
      "300/300 [==============================] - 0s - loss: 0.0991 - val_loss: 0.1895\n",
      "Epoch 21/50\n",
      "300/300 [==============================] - 0s - loss: 0.0989 - val_loss: 0.1909\n",
      "Epoch 22/50\n",
      "300/300 [==============================] - 0s - loss: 0.0986 - val_loss: 0.1921\n",
      "Epoch 23/50\n",
      "300/300 [==============================] - 0s - loss: 0.0983 - val_loss: 0.1930\n",
      "Epoch 24/50\n",
      "300/300 [==============================] - 0s - loss: 0.0981 - val_loss: 0.1935\n",
      "Epoch 25/50\n",
      "300/300 [==============================] - 0s - loss: 0.0979 - val_loss: 0.1937\n",
      "Epoch 26/50\n",
      "300/300 [==============================] - 0s - loss: 0.0977 - val_loss: 0.1935\n",
      "Epoch 27/50\n",
      "300/300 [==============================] - 0s - loss: 0.0976 - val_loss: 0.1931\n",
      "Epoch 28/50\n",
      "300/300 [==============================] - 0s - loss: 0.0975 - val_loss: 0.1925\n",
      "Epoch 29/50\n",
      "300/300 [==============================] - 0s - loss: 0.0973 - val_loss: 0.1921\n",
      "Epoch 30/50\n",
      "300/300 [==============================] - 0s - loss: 0.0972 - val_loss: 0.1916\n",
      "Epoch 31/50\n",
      "300/300 [==============================] - 0s - loss: 0.0971 - val_loss: 0.1912\n",
      "Epoch 32/50\n",
      "300/300 [==============================] - 0s - loss: 0.0970 - val_loss: 0.1908\n",
      "Epoch 33/50\n",
      "300/300 [==============================] - 0s - loss: 0.0969 - val_loss: 0.1904\n",
      "Epoch 34/50\n",
      "300/300 [==============================] - 0s - loss: 0.0968 - val_loss: 0.1897\n",
      "Epoch 35/50\n",
      "300/300 [==============================] - 0s - loss: 0.0967 - val_loss: 0.1886\n",
      "Epoch 36/50\n",
      "300/300 [==============================] - 0s - loss: 0.0966 - val_loss: 0.1871\n",
      "Epoch 37/50\n",
      "300/300 [==============================] - 0s - loss: 0.0966 - val_loss: 0.1856\n",
      "Epoch 38/50\n",
      "300/300 [==============================] - 0s - loss: 0.0965 - val_loss: 0.1846\n",
      "Epoch 39/50\n",
      "300/300 [==============================] - 0s - loss: 0.0965 - val_loss: 0.1843\n",
      "Epoch 40/50\n",
      "300/300 [==============================] - 0s - loss: 0.0964 - val_loss: 0.1845\n",
      "Epoch 41/50\n",
      "300/300 [==============================] - 0s - loss: 0.0963 - val_loss: 0.1846\n",
      "Epoch 42/50\n",
      "300/300 [==============================] - 0s - loss: 0.0962 - val_loss: 0.1846\n",
      "Epoch 43/50\n",
      "300/300 [==============================] - 0s - loss: 0.0961 - val_loss: 0.1847\n",
      "Epoch 44/50\n",
      "300/300 [==============================] - 0s - loss: 0.0961 - val_loss: 0.1847\n",
      "Epoch 45/50\n",
      "300/300 [==============================] - 0s - loss: 0.0960 - val_loss: 0.1848\n",
      "Epoch 46/50\n",
      "300/300 [==============================] - 0s - loss: 0.0959 - val_loss: 0.1848\n",
      "Epoch 47/50\n",
      "300/300 [==============================] - 0s - loss: 0.0958 - val_loss: 0.1847\n",
      "Epoch 48/50\n",
      "300/300 [==============================] - 0s - loss: 0.0958 - val_loss: 0.1845\n",
      "Epoch 49/50\n",
      "300/300 [==============================] - 0s - loss: 0.0957 - val_loss: 0.1844\n",
      "Epoch 50/50\n",
      "300/300 [==============================] - 0s - loss: 0.0956 - val_loss: 0.1843\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n0MMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1f80cab1588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''\n",
    "    LSTM will defined with 1 hidden layer composed of 50 neurons and 1 output layer composed of 1 neuron\n",
    "\n",
    "'''\n",
    "# Design network\n",
    "model =Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "\n",
    "#fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=1, shuffle=False)\n",
    "\n",
    "#plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20568059"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#predict values and calculate Root Mean Squared Error score\n",
    "yhat = model.predict(test_X)\n",
    "rmse = sqrt(mean_squared_error(test_y, yhat))\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
